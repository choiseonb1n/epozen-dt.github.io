---
title: " VGGNet"
last_modified_at: 2022-08-04
author: 김혜원
---

-------------

*이번 포스팅에서는 CNN 모델의 한 종류인 **VGGNet**에 대해 알아보겠습니다.*

---------------



> ## VGGNet?

![에러율변화](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdrYEZ4%2FbtqwpSXYd8U%2FLF8RkIhWpAmsgR67nfnZsk%2Fimg.png)

VGGNet(Visual Geometry Group Network)은 영국 옥스포드 대학의 연구팀 VGG에서 개발한 모델로 2014년에 이미지넷 인식 대회에서 준우승을 차지한 모델입니다. 이전에 나왔던 모델들이 8 layer인걸 생각하면 VGGNet은 19 layer로 깊은 신경망을 구현했는데도 오류율이 확연히 낮아진것을 위 그림에서 확인 할 수 있습니다. 같은 해 나온 GoogLeNet이 더 좋은 성능으로 우승을 차지했음에도 불구하고 VGGNet이 인기를 얻은 이유는 성능이 우수한데 구조가 단순하여 변형시키기 쉽기때문입니다. 


> ## 모델 구조 & 종류

![vggnet_종류](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbw2WnC%2FbtqKSgFqB3D%2FhYW6yfkjGFXmzMMwEM7tZ1%2Fimg.png)

 위 그림은 논문에서 진행한 실험들을 표로 정리한 것입니다. 깊이에 따른 학습률을 확인하기 위한 것으로 convolution layer의 갯수에 따라 VGG11(A), VGG11-LRN(A-LRN), VGG13(B), VGG16(C), VGG16(D), VGG19(E)입니다. A-LRN은 Normalization을 적용한 것과 아닌것의 성능을 비교하기 위해 만들어진 모델로 비교 결과 성능의 차이가 별로 없어서 B-E는 LRN을 적용한 모델이 없습니다.
 현재 모델 구성할 때 BN(Batch Normalization, 배치 정규화)을 적용하여 사용하고 있습니다.


![vgg_filter_7X7](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsqE2R%2FbtrtydXFNBU%2Fog7WaykKq2WwPcDKOiGK3k%2Fimg.png)
![vgg_filter_3X3](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdasFCD%2FbtrtyteV0nf%2FoMrbJkqUKtFFPMpaW0KxSK%2Fimg.png)

위 그림은 7X7필터와 3X3필터를 적용한 예시입니다. 논문에서 저자는 커널 사이즈를 제일 작은 3X3으로 고정시켰습니다. 예를 들어 7X7 필터와 3X3의 예시를 보겠습니다. 7X7 필터를 사용했을때는 한 번 연산하던 것을 3X3 필터를 사용하면 세 번 계산하게 됩니다. 그 결과 연산 할 때 발생하는 파라미터 수는 49에서 27로 줄어들고, ReLU의 수는 1개에서 3개로 늘어서 성능이 향상됐습니다. 

![vggnet_구조](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FK990l%2FbtqwDJ7C54R%2F664Ksm6gyTGBR1wK3YPDFk%2Fimg.png)

VGG16의 구조를 살펴보면 Convolution - Pooling - Fully_connected로 되어있습니다.
5개의 블럭을 거친 후 FC층에 도달하는데 한 블럭에 2개 ~ 3개의 convolution과 max pooling이 있습니다.
마지막은 활성화함수로 softmax를 사용하여 이미지를 분류합니다. 


----------------

>## 구현 예제

다음은 VGG-16(D) 모델의 구성을 구현한 예제입니다.
3X3 kernel을 64개 사용했으며, padding은 하지않고, ReLU 활성화 함수를 사용하였습니다.
모델 구성 후 summary()를 통해 전체 구조를 확인할 수 있습니다.

```Python

input = keras.Input(shpae=(244,244,3))
model = Sequential()
model.add(Conv2D(input,filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Flatten())
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=1000, activation="softmax"))

model.summary()

```

------------------------

참고자료
* [VGGNet 논문](https://arxiv.org/abs/1409.1556, "vggnet link")
* [VGGNet 설명1](https://bskyvision.com/504, "vggnet_explain1")
* [VGGNet 설명2](https://daechu.tistory.com/10, "vggnet_explain2")
* [VGG16 구현 예](https://yazaki.tistory.com/24, "vgg16_example")